{
    "collab_server" : "",
    "contents" : "#################################################\n#####TITANIC: MACHINE LEARNING FROM DISASTER#####\n################# Paul Le Ster ##################\n#################################################\n\n#helper functions\nlibrary(stringr)\nlibrary(ggplot2)\nlibrary(randomForest)\nlibrary(caret)\nlibrary(doSNOW)\nlibrary(rpart)\nlibrary(rpart.plot)\n\n\n\nsource(\"titanicHelper.R\")\n\n#Read in train and test data\ntrain <- read.csv(\"train.csv\", header = TRUE)\ntest <- read.csv(\"test.csv\", header = TRUE)\n\n#Combine test set and train set\ntest.survived <- data.frame(Survived = rep(\"None\", nrow(test)),test[,])\ndata.combined <- rbind(train, test.survived)\ndata.combined$Survived <- as.factor(data.combined$Survived)\ndata.combined$Pclass <- as.factor(data.combined$Pclass)\n\n\n\n###################################\n#Part 1: Understanding the data\n#Goal: Test some preliminary hypotheses, identify important features\n###################################\n\n#survival rate = 342/(342+549) = 38.38%\ntable(data.combined$Survived)\n\n\n#lets do some visualizations\n\n\n#Hypothesis 1: Rich people were more likely to survive than poor people, assuming PClass is a proxy of wealth\n#Result: Confirmed, but result isn't as stark as one might expect. 20% survival in 3rd class vs 60% survival in 1st class\nggplot(data.combined[1:891,], aes(x = Pclass, fill = factor(Survived))) + \n  geom_bar(width = 0.5) + \n  xlab(\"Wealth v Survival\") +\n  ylab(\"Total Count\") +\n  labs(fill = \"Survived\")\n\n\n#Hypothesis 2: Women more likely to survive than men\n#Result: Confirmed, but still looks like there is room for improvement. Wonder if wealthy women had an advantage...\nggplot(data.combined[1:891,], aes(x = Sex, fill = factor(Survived))) + \n  geom_bar(width = 0.5) + \n  xlab(\"Gender v Survival\") +\n  ylab(\"Total Count\") +\n  labs(fill = \"Survived\")\n\n#Hypothesis 3: Wealthy women more likely to survive than men\n#Result: Confirmed, to a high degree. It looks like if you were a female in 1st or 2nd class\nggplot(data.combined[1:891,], aes(x=Sex,fill=Survived))+\n  geom_bar(width = 0.5) +\n  facet_wrap(~Pclass)+\n  ggtitle(\"GenderxWealth v Survival\")+\n  xlab(\"Sex\")+\n  ylab(\"Total Count\")+\n  labs(fill=\"Survived\")\n\n#Hypothesis 4: Children more likely to survive than men and survive roughly as much as women\n#Result: Confirmed, to a high degree. It looks like if you were a female in 1st or 2nd class\n\n\n#Plotting out a histogram in this way doesn't really get me what I want. Let's try another proxy\nggplot(data.combined[1:891,], aes(x=Age,fill=Survived))+\n  geom_histogram(binwidth = 1) +\n  ggtitle(\"Age\")+\n  xlab(\"Age\")+\n  ylab(\"Total Count\")+\n  labs(fill=\"Survived\")\n\n#what about your title\ntitles <- NULL\nfor(i in 1:nrow(data.combined)) {\n  titles <- c(titles,getTitle(data.combined[i,\"Name\"]))\n}\ndata.combined$title <- as.factor(titles)\n\n\n#Hypothesis 4 again: Children more likely to survive than men and survive roughly as much as women\n#Result: Confirmed, to a high degree. If you are a female or child in PClass 1 or 2, you are basically guaranteed survival\n\n#Validate Assumption: Master is male child\nsummary(data.combined[which(data.combined$title==\"Master.\"),])\n\n\nggplot(data.combined[1:891,], aes(x=title,fill=Survived))+\n  geom_bar(width = 0.5) +\n  facet_wrap(~Pclass)+\n  ggtitle(\"Pclass\")+\n  xlab(\"Title\")+\n  ylab(\"Total Count\")+\n  labs(fill=\"Survived\")\n\n\n\n#Let's pause from intuitive hypotheses - why don't we do a quick scan of mutual information \"scores\"\n#Result: Title has the highest mutual information, which confirms our hypothesis that we're going down the right path\n#Other key variables look to be Sex, Age, Fare, PCLass - all in line with our thinking\n\nstr(data.combined)\nmutinformation(as.factor(data.combined$Survived[1:891]), data.combined$Pclass[1:891])\nmutinformation(as.factor(data.combined$Survived[1:891]), data.combined$Sex[1:891])\nmutinformation(as.factor(data.combined$Survived[1:891]), data.combined$Age[1:891])\nmutinformation(as.factor(data.combined$Survived[1:891]), data.combined$SibSp[1:891])\nmutinformation(as.factor(data.combined$Survived[1:891]), data.combined$Parch[1:891])\nmutinformation(as.factor(data.combined$Survived[1:891]), discretize(data.combined$Fare[1:891]))\nmutinformation(as.factor(data.combined$Survived[1:891]), data.combined$title[1:891])\n\n#Hypothesis 5- having a large family increased your chance of perishing, as harder to keep track of many\n#Result: Sort of confirmed, but data isn't clear. To be investigated further later\ndata.combined$family.size<- as.factor(c(train$SibSp,test$SibSp)+c(train$Parch,test$Parch)+1)\nggplot(data.combined[1:891,], aes(x=family.size,fill=Survived))+\n  geom_bar() +\n  ggtitle(\"Age\")+\n  xlab(\"Age\")+\n  ylab(\"Total Count\")+\n  labs(fill=\"Survived\")\n\n\n###################################\n#Part 2: Make initial predictions using Random Forests\n#Goal: Train RFs based on what we understoof about the data in part 1\n###################################\n\nrf.label <-as.factor(train$Survived)\n\n#RF.1 - PClass, Sex\n#Results: Not bad, seems indicative of our hypothesis that wealth + gender greatly affects survival\nrf.train.1 <- data.combined[1:891, c(\"Pclass\",\"Sex\")]\nset.seed(1)\nrf.1 <- randomForest(x = rf.train.1, y = rf.label, importance = TRUE, ntree = 1000)\nrf.1\nvarImpPlot(rf.1)\n\n#RF.2 - PClass, title\n#Results: Much improved from RF.1 - this is in line that our hypothesis male children (title master) also had a survival advantage\nrf.train.2 <- data.combined[1:891, c(\"Pclass\",\"title\")]\nset.seed(1)\nrf.2 <- randomForest(x = rf.train.2, y = rf.label, importance = TRUE, ntree = 1000)\nrf.2\nvarImpPlot(rf.2)\n\n\n#RF.3 - PClass, family.size\n#Results: Not great, comparatively, but in line with what we expected from our initial data exploration\nrf.train.3 <- data.combined[1:891, c(\"Pclass\",\"family.size\")]\nset.seed(1)\nrf.3 <- randomForest(x = rf.train.3, y = rf.label, importance = TRUE, ntree = 1000)\nrf.3\nvarImpPlot(rf.3)\n\n# RF.4 - PClass, title, family.size\n#Results: Very strong, 2% improvement on just PClass + Title - thought: are we overfitting?\nrf.train.4 <- data.combined[1:891, c(\"Pclass\",\"title\", \"family.size\")]\nset.seed(1)\nrf.4 <- randomForest(x = rf.train.4, y = rf.label, importance = TRUE, ntree = 1000)\nrf.4\nvarImpPlot(rf.4)\n\n\n#############################################\n#Initial Submission using RF.4\ntest.only <- data.combined[892:1309, c(\"Pclass\",\"title\", \"family.size\")]\nrf.4.predictions <- predict(rf.4, test.only)\nsubmit <- data.frame(PassengerId = rep(892:1309), Survived = rf.4.predictions)\nwrite.csv(submit,file = \"submission_v1.csv\", row.names = FALSE)\n#Results:0.79426 - This is lower than our OOB estimate, which makes me wonder if we are overfitting. Let's investigate with Cross Validation\n##############################################\n\n\n###################################\n#Part 3: Cross Validation \n###################################\n\n\n#cross validation\n\n#10 fold cross validation, repeated 10 times\n#split data into 10 chunks, take one chunk and use as test set to train the remaining 9\n#and iterate\n\n#stratified CV - make sure that ratio of survived and perished is same\n#across all chunks\n\nset.seed(2348)\ncv.10.folds <- createMultiFolds(rf.label, k=10, times = 10)\n\n#check stratification\ntable(rf.label)\n\ntable(rf.label[cv.10.folds[[33]]])\n\n#set up caret's trancontrol object per above\nctrl.1 <- trainControl(method=\"repeatedcv\", number = 10, repeats = 10, index = cv.10.folds)\n\n#set up doSNOW package for multi core training\ncl<- makeCluster(4, type = \"SOCK\")\nregisterDoSNOW(cl)\n\n#set seed for reproducibility and train\nset.seed(34324)\nrf.5.cv.1 <- train(x = rf.train.5, y = rf.label, method = \"rf\", tuneLength = 3, ntree = 1000, trControl = ctrl.1)\n\n#shut down cluster\nstopCluster(cl)\n\n#results\nrf.5.cv.1\n\n\n#this is still too optimistic. lower than what i got on kaggle submission\n# I might still be overfitting\n# repeat cross val with smaller number of folds\n\nset.seed(5983)\ncv.5.folds <- createMultiFolds(rf.label, k=5, times = 10)\n\n#set up caret's trancontrol object \nctrl.2 <- trainControl(method=\"repeatedcv\", number = 5, repeats = 10, index = cv.5.folds)\n\n#set up doSNOW package for multi core training\ncl<- makeCluster(4, type = \"SOCK\")\nregisterDoSNOW(cl)\n\n#set seed for reproducibility and train\nset.seed(89472)\nrf.5.cv.2 <- train(x = rf.train.5, y = rf.label, method = \"rf\", tuneLength = 3, ntree = 1000, trControl = ctrl.2)\n\n#shut down cluster\nstopCluster(cl)\n\n#results\nrf.5.cv.2\n\n#let's try 3 fold\n\nset.seed(37596)\ncv.3.folds <- createMultiFolds(rf.label, k=3, times = 10)\n\n#set up caret's trancontrol object \nctrl.3 <- trainControl(method=\"repeatedcv\", number = 3, repeats = 10, index = cv.3.folds)\n\n#set up doSNOW package for multi core training\ncl<- makeCluster(4, type = \"SOCK\")\nregisterDoSNOW(cl)\n\n#set seed for reproducibility and train\nset.seed(94622)\nrf.5.cv.3 <- train(x = rf.train.5, y = rf.label, method = \"rf\", tuneLength = 3, ntree = 64, trControl = ctrl.3)\n\n#shut down cluster\nstopCluster(cl)\n\n#results\nrf.5.cv.3\n\n#so going forward, our explaratory modeling is going to be based on 3 fold CV repeated 10 times, \n#THis is where we will determine if this feature improves our random forest? yes or no\n\n###################################\n#Part 4: More Feature Engineering\n###################################\n\n#more exploratory modelling\n#Moving forward we're going to use 3 fold cross validation repeated 10 times\n#we will generate a single tree to try and understand our features better \n\n\n#Tree #1 - Pclass, title, family.size\n\nrpart.cv <- function(seed, training, labels, ctrl){\n  cl<- makeCluster(4,type = \"SOCK\")\n  registerDoSNOW((cl))\n  set.seed(seed)\n  rpart.cv <- train(x=training, y = labels, method= \"rpart\", tuneLength = 30, trControl = ctrl)\n  stopCluster(cl)\n  return(rpart.cv)\n}\n\n#grab features from best RF, run single tree for further investigation\nfeatures <- c(\"Pclass\",\"title\",\"family.size\")  \nrpart.train.1 <-data.combined[1:891,features]\nrpart.1.cv.1 <- rpart.cv(1, rpart.train.1, rf.label, ctrl.3)\nrpart.1.cv.1\n\n#display tree\nprp(rpart.1.cv.1$finalModel, type = 0, extra = 1, under = TRUE)\n\n#Takeaways from the tree\n# 1) What's going on with \"Other\" in the title. Let's do some digging and figure out if we can refine\n# 2) If you are a female or child and you are not in 3rd class, you survive 95% of the time. Let's focus our efforts elsewhere\n# 3) Family size seems arbitrary when seen this way - looks like we are probably overfitting\n\n#Action item #1 - knock out the \"Others\" in title\ntemp.title <-str_split(sapply(str_split(data.combined$Name,\",\"),\"[\", 2),\" \")\ntitles <- sapply(temp.title, \"[\",2)\nunique(titles)\n#A little online research yields that Mlle, Dona, etc are foreign names for Mr, Mrs, etc\n#For simplicity, let's group all the females under Mrs\n\n\n#looking for something that could refine our other results\n#look at SIr, The, Dona - these could be titles that change results\n#some indicate gender, which is important for us. \n\n\n#title fixing\n#putting all elderly females under Mrs - data exploration does not indicate any major trends\n#putting all younger ladies under Miss\n#Putting all male titles under Mr - data exploration does not indicate any major trends\ntitles[titles %in% c(\"Ms.\",\"Mlle.\")] <- \"Miss.\"\ntitles[titles %in% c(\"Mme.\",\"Lady.\",\"Dona.\",\"the\")] <- \"Mrs.\"\ntitles[titles %in% c(\"Jonkheer.\",\"Don.\", \"Col.\",\"Capt.\", \"Major.\",\"Rev.\", \"Sir.\",\"Dr.\")] <- \"Mr.\"\n#pop into data.combined and correct for any females that may have male titles\ndata.combined$title.2 <- as.factor(titles)\nindexes <- which(data.combined$title.2 == \"Mr.\" & data.combined$Sex == \"female\")\ndata.combined$title.2[indexes] <- \"Mrs.\"\ntable(data.combined$title.2)\n\n#visually check - yep, Mrs, Miss, Master in 1,2 class overwhelmingly survive\nggplot(data.combined[1:891,], aes(x=title.2,fill=Survived)) +\n  geom_bar() + \n  facet_wrap(~Pclass) +\n  ggtitle(\"survival rates for new titles by pclass\")\n\n#Tree #2 - Pclass, title.2, family.size\nfeatures <- c(\"Pclass\",\"title.2\",\"family.size\")\nrpart.train.2 <- data.combined[1:891,features]\nrpart.2.cv.1 <-rpart.cv(1,rpart.train.2,rf.label,ctrl.3)\nrpart.2.cv.1\nprp(rpart.2.cv.1$finalModel,type= 0, extra = 1, under = TRUE)\n\n#Takeaways from the tree\n# 1) \"Other\" title resolved. It now appears that we have a clean cut between males and everyone else\n# 2) Family size seems arbitrary when seen this way - looks like we are probably overfitting - let's focus on this now\n\n\n\n\n#poking through data, we see that our family size feature is off. There does seem to be some mild correlation, but it may be worth it to put aside and try something new\n#In a similar vein, lets look at party size. Data exploration suggests that parties travelling together have the same ticket number\n#Further, this gives us a method for calculating Fare in an interesting way, which was previously dismissed because it was the Fare of the entire party\n\nparty.size <- rep(0,nrow(data.combined))\naverage.party.fare <- rep(0.0, nrow(data.combined))\n\ntickets.unique <- unique(data.combined$Ticket)\n\nfor(i in 1:length(tickets.unique)){\n  current <- tickets.unique[i]\n  indexes <- which(data.combined$Ticket == current)\n  current.average.fare<-data.combined[indexes[1],\"Fare\"]/length(indexes)\n  \n  for(k in 1:length(indexes)){\n    party.size[indexes[k]] <- length(indexes)\n    average.party.fare[indexes[k]] <- current.average.fare\n  }\n  \n  \n}\n\ndata.combined$party.size <- party.size\ndata.combined$average.party.fare <- average.party.fare\nView(data.combined)\n#hacky fix for missing value\ndata.combined[is.na(average.party.fare), \"average.party.fare\"] <- 7.840\n\n\n#let's see if feature engineering was good\n\nfeatures <- c(\"Pclass\", \"title.2\", \"party.size\", \"average.party.fare\")\nrpart.train.3 <-data.combined[1:891, features]\n\nrpart.3.cv.1 <-rpart.cv(1, rpart.train.3, rf.label, ctrl.3)\nrpart.3.cv.1\n\nprp(rpart.3.cv.1$finalModel, type =0, extra = 1, under = TRUE)\n\n\n#RF.5 - Plug these new engineering features into our random forest\n\nfeatures <- c(\"Pclass\", \"title.2\", \"party.size\", \"average.party.fare\")\nrf.train.5 <-data.combined[1:891, features]\nset.seed(1)\nrf.5 <- randomForest(x=rf.train.5, y=rf.label, ntree=1000)\nrf.5\n \n#############################################\n#Final Submission using RF.5\ntest.only <- data.combined[892:1309, c(\"Pclass\",\"title.2\", \"party.size\", \"average.party.fare\")]\nrf.5.prediction <- predict(rf.5, test.only)\ntable(rf.5.prediction)\nsubmit <- data.frame(PassengerId = rep(892:1309), Survived = rf.5.prediction)\nwrite.csv(submit,file = \"submission_v2.csv\", row.names = FALSE)\n#Results:0.80383 - mprovement over our last result of 0.79426 + plus hypothesize that it will do better at conclusion of competition as used cross validation instead of just OOB\n##############################################\n\n#glaring area where model is messing up is the males. Just don't have good features to understand whether an adult males was likely to survive\n\n\nrich.guys.i <- which(data.combined$title.2 == \"Mr.\" & data.combined$Pclass == \"1\" & )\nrich.guys <- data.combined[rich.guys.i, ]\nsummary(rich.guys)\n\nggplot(rich.guys[rich.guys$Survived != \"None\",], aes(x = average.party.fare, fill = Survived)) +\n  geom_density(alpha = 0.5) +\n  ggtitle(\"Survival Rates 1st Class 'Mr.' by average fare\")\n\n#Unsure how to move forward. Doesn't seem to be any clear indicators of propensity to survive with first class male adults\n#Hypothesis - Could cabin placement be an issue? Whereas women and children almost definitely got seats, could it have been on a first-come-first serve basis for men, \n#meaning that the closest cabins got lifeboats first? Seems extremely unlikely but who knows.\n\n",
    "created" : 1476292039449.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "1846451470",
    "id" : "7B20160B",
    "lastKnownWriteTime" : 1481265427,
    "last_content_update" : 1481265427253,
    "path" : "~/datascience/titanic/titanicDataAnalysis.R",
    "project_path" : "titanicDataAnalysis.R",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "relative_order" : 0,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}